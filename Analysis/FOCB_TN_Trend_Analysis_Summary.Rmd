---
title: "Analysis of Friends of Casco Bay TN Data"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership."
date: "04/26/2021"
output:
  github_document:
    toc: true
    fig_width: 5
    fig_height: 4
---

<img
    src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
    style="position:absolute;top:10px;right:50px;" />

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center',
                      fig.width = 5, fig.height = 4,
                      collapse = TRUE, comment = "#>")
```

# Introduction
This notebook Looks at TN numbers from Friends of Casco Bay samples.

# Load Libraries
```{r load_libraries}
library(readxl)
library(tidyverse)

library(mgcv)    # For generalized linear models
library(emmeans)

library(mblm)     # Median-based linear models - -but only single predictor

library(CBEPgraphics)
load_cbep_fonts()
theme_set(theme_cbep())
```

# Load Data
## Folder References
```{r folder_refs}
sibfldnm <- 'Data'
parent <- dirname(getwd())
sibling <- file.path(parent,sibfldnm)
```

## Load Data
The data we use here has had a number of suspiciously high NH4 values removed.
See "FOCB_Nutrients_Combined.Rmd" for details and explanation.
```{r load_data}
strict_data <- read_csv(file.path(sibling, 
                                 "focb_n_data_strict.csv"))%>%
  mutate(month = factor(month, levels = month.abb),
         yearf = factor(year)) %>%
  mutate(dt = as.Date(dt))
```

# Station Names
```{r folder_refs_2}
fn <- 'FOCB Monitoring Sites SHORT NAMES.xlsx'
names_df <- read_excel(file.path(sibling, fn))
```

# Data Review
TN shows a sparse, sampling pattern, with most samples at just
a handful of sites before 2017.

## Data Distributions
```{r tn)hist}
ggplot(strict_data , aes(tn)) +
  geom_histogram()
```

Note the four very high values.  Only one of those is relevant to this analysis.
That is the highest observed TN value, at over 3 mg/l at site SMT50.

We have serious doubts about the validity of that observation, and it tends to
have very high leverage in model fits, so we chose to omit it - -even though
we have o basis in our source data to believe that the data is in error (except
for a value more than double the next highest observed TN value).  

# Trend Data
Few stations have data from more than a few years.  TN data has been collected 
over the past couple of years, at several stations in the mid 2000s, and at a
handful of stations pretty much every year since 2001.  Generally the rule we 
have used to examine trends is to focus on sites with relatively complete 
records, say at least two of the last five years and at least
ten years total.  

## Identify Trend Stations
```{r which_stations}
trend_sites <- strict_data %>%
  group_by(station, year) %>%
  summarize(was_sampled =  ! all(is.na(tn)),
            .groups = 'drop_last') %>%
  summarize(last_5 = sum(was_sampled & year > 2014),
            total = sum(was_sampled),
            .groups = 'drop') %>%
  filter(total >= 10, last_5 >= 2) %>%
  pull(station)
trend_sites
```

## Generate Trend Data
Note that we remove the extreme value from the data here.
```{r make_trend_data}
trend_data <- strict_data %>%
   filter(station %in% trend_sites) %>%
   mutate(tn = if_else(tn >= 1.5, NA_real_, tn)) %>%
   filter(! is.na(tn)) %>%
   mutate(station_name = names_df$Alt_Name[match(station,
                                                names_df$Station_ID)]) %>%
   mutate(station = factor(station),
          station_name = factor(station_name)) %>%
   mutate(station = fct_reorder(station, tn, na.rm = TRUE),
         station_name = fct_reorder(station_name, tn, na.rm = TRUE)) %>%
   relocate(station_name, .after = station) %>%
   select(-contains('n_N', ignore.case = FALSE), -contains('depth'), -organic_N)
```

### Data Distribution
```{r trend_data_histogram}
ggplot(trend_data, aes(tn)) +
  geom_histogram()
```

### Data Prevalence
```{r trend_data_months}
xtabs(~ month + station, data = trend_data )%>%
  as_tibble() %>%
  mutate(month = factor(month, levels = month.abb)) %>%
  filter(n>0) %>%

  ggplot(aes(station, month, fill = sqrt(n))) +
  geom_tile() +
  theme_cbep(base_size = 12) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .25))
```
We have few cold weather samples, but fairly good coverage from may through 
October.

```{r trend_data_years}
xtabs(~ year + station, data = trend_data) %>%
  as_tibble() %>% 
  filter(n>0) %>%

  ggplot(aes(station, year, fill = sqrt(n))) +
  geom_tile() +
  theme_cbep(base_size = 12) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .25))
```
Similarly, data coverage by year is pretty good for all these sites.

```{r trend_data_times}
xtabs(~ year + month, data = trend_data) %>%
  as_tibble() %>% 
  mutate(month = factor(month, levels = month.abb))  %>%
  filter(n>0) %>%

  ggplot(aes(month, year, fill = sqrt(n))) +
  geom_tile() +
  theme_cbep(base_size = 12) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .25))
```

We see the change in FOCB monitoring practices in 2017.  Winter data is not
available in recent_years. If there are seasonal TN trends, as our analysis of
the recent data suggests, annual averages may be biased. We would be better
served to restrict attention to the summer months, where sampling has been most
consistent over time.  We focus on May through October data.

## Generate Core Months Trend Data
```{r make_core_months_data}
core_months_data <- trend_data %>%
  filter(month %in% month.abb[5:10])
```

## Models
### Initial Linear Model
```{r trend_lm_1}
trnd_lm_1 <- lm(log(tn) ~ (year + station_name + month)^2 , 
                data = core_months_data)
anova(trnd_lm_1)
```
Note that in this setting, there is no reason to believe all stations show the 
same trend, so a model that does not fit trends separately for each station
(via station x year interaction term) is of limited value, even if the model
(as here) suggests the interaction is not important.

We could be more cautious about claiming a trend by fitting a hierarchical model
that treats years as a random factor as well.  That would account for high
intra-year autocorrelation. We choose not to do that here.

```{r trend_lm_step}
trnd_lm_2 <- step(trnd_lm_1)
```

```{r anova_trend_lm_2}
anova(trnd_lm_2)
```

```{r summary_trend_lm_2}
summary(trnd_lm_2)
```

So the obvious linear model analysis suggests there is a weak negative linear
trend, and there are no differences in trend among stations.

The month to month terms have high standard errors, and the possible interaction
rests principally on the month of August.

```{r trend_lm_2_diagnostics}
oldpar <- par(mfrow=c(2,2))
plot(trnd_lm_2)
par(oldpar)
```
Other than the heavy tails and slight skewness of the residuals, model
diagnostics are pretty good, suggesting these conclusions will be robust to most
other reasonable model specifications.

### Check for Non-linear Patterns
We start by fitting a polynomial 
```{r trend_polynomial}
trnd_lm_3 <- lm(log(tn) ~ poly(year,2) + station + poly(year,2):station + 
                                month + month:year, data = core_months_data)
anova(trnd_lm_3)
anova(trnd_lm_2, trnd_lm_3, test = 'F')
```

So there is no evidence that we need the non-linear terms to capture the 
long-term trend.

### Final Linear Model
We force-fit separate slopes for each station, and drop the year by month 
interaction term as being of limited interest, and possibly misleading.
```{r trend_lm_final}
trnd_lm <- lm(log(tn) ~ station_name + station_name:year + month,
                data = core_months_data)
anova(trnd_lm)
summary(trnd_lm)
```

We have significant trends at three sites:  Broad Sound, Clapboard 
Island, and Fort Gorges.

# Median-Based Models
We double check regression results using more robust regression.  There is
little indication that this is strictly necessary, as model diagnostics are not
too bad, but it's worth checking all the same.

We set up a nested tibble to hold multiple models.

```{r}
mods <-trend_data %>%
  group_by(station) %>%
  summarize(station = first(station), .groups = 'drop')
```

```{r}
lmods <- list()
for (n in seq_along(mods$station)) {
  site <- mods$station[n]
  tmp <- trend_data %>%
    filter(station == site) %>%
    mutate(logval = log(tn))
  rlm <- mblm(logval ~ year, data = tmp)
  lmods[[site]] <- rlm
}

mods$rlm <- lmods
rm(lmods, rlm, tmp, site)
```

## Identify Significant Regressions
From the log-linear models.  We use P < 0.025 because of relatively poor model
diagnostics.  We don't want to trust "borderline" P values, and we don't want to
go to the trouble (for this purpose) of using bootstraps or other methods to
assess confidence limits more rigorously.

```{r}
rlm_p_vals <- lapply(mods$rlm, function(m) summary(m)$coefficients[2,4])
names(rlm_p_vals) <- mods$station
cat('\n')
rlm_p_vals
```

We also like to check significance using the closely related Kendall's Tau.

```{r}
for (n in seq_along(mods$station)) {
  site <- mods$station[n]
  tmp <- trend_data %>%
    filter(station == site)
   cat(paste0('\n', site, '\n'))
   print(cor.test(log(tmp$tn), tmp$year, method = 'kendall')) }
```
```{r}
cor(log(tmp$tn), tmp$year, method = 'kendall')
```

That shows similar results, but throws the significant decline at Quahog Bay
into question (0.1 < p < 0.05) as well. That reflects the importance of one
relatively high TN value from the early part of the record.  It may also reflect
the sparse modeling. MBLM is unable to handle multiple predictors, so we can not
account for season here.


